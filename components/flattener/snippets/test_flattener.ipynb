{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel Flattener - Testing Notebook\n",
    "\n",
    "Interactive notebook for testing and exploring the Excel Flattener.\n",
    "\n",
    "## Features Tested\n",
    "\n",
    "- Workbook flattening\n",
    "- Formula extraction\n",
    "- Value extraction (literal and computed)\n",
    "- VBA extraction\n",
    "- Chart, table, and named range extraction\n",
    "- Manifest generation\n",
    "\n",
    "## Setup\n",
    "\n",
    "Ensure dependencies are installed:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "pip install jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Edit this cell to customise settings for testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURATION =====\n",
    "# Edit these variables to customise your test run\n",
    "\n",
    "# Test file to flatten\n",
    "TEST_EXCEL_FILE = \"./sample.xlsm\"  # Change to your test file\n",
    "TEST_EXCEL_FILE = \"./sample.xlsx\"  # Change to your test file\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"./tmp/flats\"\n",
    "\n",
    "# Include computed values?\n",
    "INCLUDE_COMPUTED = True\n",
    "\n",
    "# Logging level (DEBUG, INFO, WARNING, ERROR)\n",
    "LOG_LEVEL = \"INFO\"\n",
    "\n",
    "# Extraction timeout (seconds)\n",
    "EXTRACTION_TIMEOUT = 900\n",
    "\n",
    "# Maximum file size (MB)\n",
    "MAX_FILE_SIZE_MB = 200\n",
    "\n",
    "# Test for Manifest\n",
    "ORIGIN_REPO = \"Origin repo test\"\n",
    "ORIGIN_PATH = \"Origin path test\"\n",
    "ORIGIN_COMMIT = \"Origin commit test\"\n",
    "ORIGIN_COMMIT_MESSAGE = \"Origin commit message test\"\n",
    "\n",
    "# ========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-30 11:31:52] \u001b[32mINFO    \u001b[0m | root         | Logging initialised (level: INFO, file: tmp/logs/notebook_20251030_113152.log)\n",
      "✓ Imports complete\n",
      "✓ Test file: ./sample.xlsx\n",
      "✓ Output directory: ./tmp/flats\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add parent directory to path to import from src\n",
    "sys.path.insert(0, str(Path('..').resolve()))\n",
    "\n",
    "from src import Flattener, setup_logging\n",
    "from src.utils import get_file_hash\n",
    "\n",
    "# Setup logging\n",
    "setup_logging(log_level=LOG_LEVEL, log_dir='./tmp/logs', component='notebook')\n",
    "\n",
    "print(\"✓ Imports complete\")\n",
    "print(f\"✓ Test file: {TEST_EXCEL_FILE}\")\n",
    "print(f\"✓ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Test file found\n",
      "  Name: sample.xlsx\n",
      "  Size: 0.01 MB (8,658 bytes)\n",
      "  Extension: .xlsx\n",
      "\n",
      "  Computing SHA256...\n",
      "  SHA256: 4f4cb6ba08415d0de58f50d614e08b7effee0975ba4fa11dd8782d1e38181c86\n",
      "  Short hash: 4f4cb6ba08415d0d...\n"
     ]
    }
   ],
   "source": [
    "test_file = Path(TEST_EXCEL_FILE)\n",
    "\n",
    "if not test_file.exists():\n",
    "    print(f\"✗ Test file not found: {test_file}\")\n",
    "    print(\"\\nPlease create a test Excel file or update TEST_EXCEL_FILE in the config cell.\")\n",
    "else:\n",
    "    # File information\n",
    "    size_bytes = test_file.stat().st_size\n",
    "    size_mb = size_bytes / (1024 * 1024)\n",
    "    \n",
    "    print(f\"✓ Test file found\")\n",
    "    print(f\"  Name: {test_file.name}\")\n",
    "    print(f\"  Size: {size_mb:.2f} MB ({size_bytes:,} bytes)\")\n",
    "    print(f\"  Extension: {test_file.suffix}\")\n",
    "    \n",
    "    # Calculate hash\n",
    "    print(f\"\\n  Computing SHA256...\")\n",
    "    file_hash = get_file_hash(test_file)\n",
    "    print(f\"  SHA256: {file_hash}\")\n",
    "    print(f\"  Short hash: {file_hash[:16]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flattener Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-30 11:32:08] \u001b[32mINFO    \u001b[0m | src.flattener | Flattener initialised (output: tmp/flats, computed: True, timeout: 900s)\n",
      "✓ Flattener created\n",
      "  Output directory: ./tmp/flats\n",
      "  Include computed: True\n",
      "  Timeout: 900s\n",
      "  Max file size: 200MB\n"
     ]
    }
   ],
   "source": [
    "flattener = Flattener(\n",
    "    output_dir=Path(OUTPUT_DIR),\n",
    "    include_computed=INCLUDE_COMPUTED,\n",
    "    timeout=EXTRACTION_TIMEOUT,\n",
    "    max_file_size_mb=MAX_FILE_SIZE_MB\n",
    ")\n",
    "\n",
    "print(\"✓ Flattener created\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  Include computed: {INCLUDE_COMPUTED}\")\n",
    "print(f\"  Timeout: {EXTRACTION_TIMEOUT}s\")\n",
    "print(f\"  Max file size: {MAX_FILE_SIZE_MB}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | ✓ File validated (0.0MB)\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | ======================================================================\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Starting extraction: sample.xlsx\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | ======================================================================\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | File hash: 4f4cb6ba08415d0d...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Flat root: tmp/flats/sample-flat-20251030T113212Z-4f4cb6ba\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Loading workbook...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | ✓ Workbook loaded (3 sheets)\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Extracting metadata...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.metadata | ✓ Extracted metadata (author: Excel Flattener Test Suite, sheets: 3)\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Extracting structure...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.workbook_structure | ✓ Extracted structure for 3 sheets\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Extracting sheets...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener |   Processing sheet: Sales Data\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 7 formulas from Sales Data\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 26 literal values from Sales Data\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 7 computed values from Sales Data\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 35 formatted cells from Sales Data\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener |   Processing sheet: Summary\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 3 formulas from Summary\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 4 literal values from Summary\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 3 computed values from Summary\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 12 formatted cells from Summary\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener |   Processing sheet: Configuration\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 0 formulas from Configuration\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 4 literal values from Configuration\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 0 computed values from Configuration\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.sheets   | ✓ Extracted 4 formatted cells from Configuration\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Extracting VBA...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.vba      | ✓ No VBA macros detected\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Extracting tables...\n",
      "[2025-10-30 11:32:12] \u001b[33mWARNING \u001b[0m | src.tables   | Error extracting table SalesTable: 'str' object has no attribute 'ref'\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.tables   | ✓ Extracted 0 tables\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.tables   | ✓ Extracted 0 autofilters\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Extracting charts...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.charts   | ✓ Extracted 1 charts\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | Extracting named ranges...\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.named_ranges | ✓ Extracted 2 named ranges\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.manifest | Saved manifest: tmp/flats/sample-flat-20251030T113212Z-4f4cb6ba/manifest.json\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | ======================================================================\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | ✓ Extraction complete: sample-flat-20251030T113212Z-4f4cb6ba\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener |   Total files: 19\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener |   Warnings: 0\n",
      "[2025-10-30 11:32:12] \u001b[32mINFO    \u001b[0m | src.flattener | ======================================================================\n",
      "\n",
      "✓ Flattening complete!\n",
      "  Duration: 0.07s\n",
      "  Output: tmp/flats/sample-flat-20251030T113212Z-4f4cb6ba\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "try:\n",
    "    flat_root = flattener.flatten(\n",
    "        excel_file=test_file,\n",
    "        origin_repo=ORIGIN_REPO,\n",
    "        origin_path=ORIGIN_PATH,\n",
    "        origin_commit=ORIGIN_COMMIT,\n",
    "        origin_commit_message=ORIGIN_COMMIT_MESSAGE\n",
    "    )\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\n✓ Flattening complete!\")\n",
    "    print(f\"  Duration: {duration:.2f}s\")\n",
    "    print(f\"  Output: {flat_root}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    end_time = datetime.now()\n",
    "    duration = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\n✗ Flattening failed after {duration:.2f}s\")\n",
    "    print(f\"  Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_path = flat_root / 'manifest.json'\n",
    "\n",
    "with open(manifest_path, 'r', encoding='utf-8') as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "print(\"Manifest Overview:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Workbook: {manifest['workbook_filename']}\")\n",
    "print(f\"Extracted at: {manifest['extracted_at']}\")\n",
    "print(f\"Extractor version: {manifest['extractor_version']}\")\n",
    "print(f\"Include computed: {manifest['include_computed']}\")\n",
    "print(f\"\\nOriginal file hash: {manifest['original_sha256'][:16]}...\")\n",
    "\n",
    "print(f\"\\nSheets ({len(manifest['sheets'])}):\")\n",
    "for sheet in manifest['sheets']:\n",
    "    visibility = '👁️ ' if sheet['visible'] else '🔒 '\n",
    "    print(f\"  {visibility}{sheet['index']}. {sheet['name']} (ID: {sheet['sheetId']})\")\n",
    "\n",
    "print(f\"\\nFiles generated: {len(manifest['files'])}\")\n",
    "for file_info in manifest['files'][:10]:  # Show first 10\n",
    "    print(f\"  - {file_info['path']}\")\n",
    "if len(manifest['files']) > 10:\n",
    "    print(f\"  ... and {len(manifest['files']) - 10} more\")\n",
    "\n",
    "if manifest['warnings']:\n",
    "    print(f\"\\n⚠️  Warnings ({len(manifest['warnings'])}):\")\n",
    "    for warning in manifest['warnings']:\n",
    "        print(f\"  - {warning}\")\n",
    "else:\n",
    "    print(f\"\\n✓ No warnings\")\n",
    "\n",
    "if 'origin' in manifest:\n",
    "    origin = manifest['origin']\n",
    "    print(f\"\\nOrigin:\")\n",
    "    print(f\"  Repo: {origin['origin_repo']}\")\n",
    "    print(f\"  Path: {origin['origin_path']}\")\n",
    "    print(f\"  Commit: {origin['origin_commit']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = flat_root / 'metadata.txt'\n",
    "\n",
    "if metadata_path.exists():\n",
    "    print(\"Workbook Metadata:\")\n",
    "    print(\"=\" * 50)\n",
    "    with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "        # Skip header\n",
    "        lines = f.readlines()[3:]\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                print(f\"  {line.rstrip()}\")\n",
    "else:\n",
    "    print(\"No metadata file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_path = flat_root / 'structure.txt'\n",
    "\n",
    "if structure_path.exists():\n",
    "    print(\"Workbook Structure:\")\n",
    "    print(\"=\" * 50)\n",
    "    with open(structure_path, 'r', encoding='utf-8') as f:\n",
    "        # Skip header\n",
    "        lines = f.readlines()[3:]\n",
    "        print(''.join(lines))\n",
    "else:\n",
    "    print(\"No structure file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Sheet Data (First Sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets_dir = flat_root / 'sheets'\n",
    "\n",
    "if sheets_dir.exists():\n",
    "    # Get first sheet directory\n",
    "    sheet_dirs = sorted(sheets_dir.iterdir())\n",
    "    if sheet_dirs:\n",
    "        first_sheet = sheet_dirs[0]\n",
    "        print(f\"Sheet: {first_sheet.name}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Formulas\n",
    "        formulas_path = first_sheet / 'formulas.txt'\n",
    "        if formulas_path.exists():\n",
    "            with open(formulas_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()[3:]  # Skip header\n",
    "                formula_count = len([l for l in lines if l.strip()])\n",
    "                print(f\"\\nFormulas ({formula_count}):\")\n",
    "                for line in lines[:5]:  # Show first 5\n",
    "                    if line.strip():\n",
    "                        print(f\"  {line.rstrip()}\")\n",
    "                if formula_count > 5:\n",
    "                    print(f\"  ... and {formula_count - 5} more\")\n",
    "        \n",
    "        # Literal values\n",
    "        literal_path = first_sheet / 'literal-values.txt'\n",
    "        if literal_path.exists():\n",
    "            with open(literal_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()[3:]  # Skip header\n",
    "                value_count = len([l for l in lines if l.strip()])\n",
    "                print(f\"\\nLiteral Values ({value_count}):\")\n",
    "                for line in lines[:5]:  # Show first 5\n",
    "                    if line.strip():\n",
    "                        print(f\"  {line.rstrip()}\")\n",
    "                if value_count > 5:\n",
    "                    print(f\"  ... and {value_count - 5} more\")\n",
    "        \n",
    "        # Computed values\n",
    "        computed_path = first_sheet / 'computed-values.txt'\n",
    "        if computed_path.exists():\n",
    "            with open(computed_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()[3:]  # Skip header\n",
    "                value_count = len([l for l in lines if l.strip()])\n",
    "                print(f\"\\nComputed Values ({value_count}):\")\n",
    "                for line in lines[:5]:  # Show first 5\n",
    "                    if line.strip():\n",
    "                        print(f\"  {line.rstrip()}\")\n",
    "                if value_count > 5:\n",
    "                    print(f\"  ... and {value_count - 5} more\")\n",
    "    else:\n",
    "        print(\"No sheets found\")\n",
    "else:\n",
    "    print(\"No sheets directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine VBA (if present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vba_dir = flat_root / 'vba'\n",
    "\n",
    "if vba_dir.exists():\n",
    "    print(\"VBA Macros:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Summary\n",
    "    summary_path = vba_dir / 'vba-summary.txt'\n",
    "    if summary_path.exists():\n",
    "        with open(summary_path, 'r', encoding='utf-8') as f:\n",
    "            print(f.read())\n",
    "    \n",
    "    # List VBA files\n",
    "    vba_files = list(vba_dir.glob('*.vba'))\n",
    "    if vba_files:\n",
    "        print(f\"\\nVBA Modules ({len(vba_files)}):\")\n",
    "        for vba_file in vba_files:\n",
    "            with open(vba_file, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                lines = f.readlines()\n",
    "                line_count = len(lines)\n",
    "                print(f\"  - {vba_file.name} ({line_count} lines)\")\n",
    "else:\n",
    "    print(\"No VBA macros found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named ranges\n",
    "named_ranges_path = flat_root / 'named-ranges.txt'\n",
    "if named_ranges_path.exists():\n",
    "    with open(named_ranges_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        # Count names\n",
    "        name_count = content.count('Name: ')\n",
    "        print(f\"Named Ranges: {name_count}\")\n",
    "\n",
    "# Tables\n",
    "tables_path = flat_root / 'tables.txt'\n",
    "if tables_path.exists():\n",
    "    with open(tables_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        table_count = content.count('Table: ')\n",
    "        print(f\"Tables: {table_count}\")\n",
    "\n",
    "# AutoFilters\n",
    "autofilters_path = flat_root / 'autofilters.txt'\n",
    "if autofilters_path.exists():\n",
    "    with open(autofilters_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        filter_count = content.count('Sheet: ')\n",
    "        print(f\"AutoFilters: {filter_count}\")\n",
    "\n",
    "# Charts\n",
    "charts_path = flat_root / 'charts.txt'\n",
    "if charts_path.exists():\n",
    "    with open(charts_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        chart_count = content.count('Chart ')\n",
    "        print(f\"Charts: {chart_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_tree(directory, prefix='', max_depth=3, current_depth=0):\n",
    "    \"\"\"Print directory tree.\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    entries = sorted(directory.iterdir(), key=lambda x: (not x.is_dir(), x.name))\n",
    "    \n",
    "    for i, entry in enumerate(entries):\n",
    "        is_last = i == len(entries) - 1\n",
    "        current_prefix = '└── ' if is_last else '├── '\n",
    "        print(f\"{prefix}{current_prefix}{entry.name}\")\n",
    "        \n",
    "        if entry.is_dir():\n",
    "            extension = '    ' if is_last else '│   '\n",
    "            print_tree(entry, prefix + extension, max_depth, current_depth + 1)\n",
    "\n",
    "print(\"\\nOutput Directory Tree:\")\n",
    "print(\"=\" * 50)\n",
    "print(flat_root.name)\n",
    "print_tree(flat_root, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtraction Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Input file: {test_file}\")\n",
    "print(f\"Output directory: {flat_root}\")\n",
    "print(f\"Duration: {duration:.2f}s\")\n",
    "print(f\"Files generated: {len(manifest['files'])}\")\n",
    "print(f\"Sheets: {len(manifest['sheets'])}\")\n",
    "print(f\"Warnings: {len(manifest['warnings'])}\")\n",
    "print(f\"Include computed: {INCLUDE_COMPUTED}\")\n",
    "print(\"\\n✓ Testing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
